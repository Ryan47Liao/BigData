{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Map\n",
    "### Restriction, don't take the short cut of using Pool packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadWithReturnValue(Thread):\n",
    "    \"This subclass is created to get results from a thread,without needing to modify mutable objects\"\n",
    "    def __init__(self, group=None, target=None, name=None,\n",
    "                args=(), kwargs={}, Verbose=None):\n",
    "        Thread.__init__(self, group, target, name, args, kwargs)\n",
    "        self._return = None\n",
    "    def run(self):\n",
    "        #print(type(self._target))\n",
    "        if self._target is not None:\n",
    "            if type(self._args) == str:\n",
    "                self._return = self._target(self._args,\n",
    "                                                **self._kwargs)\n",
    "            else:\n",
    "                self._return = self._target(*self._args,\n",
    "                                **self._kwargs)\n",
    "    def join(self, *args):\n",
    "        Thread.join(self, *args)\n",
    "        return self._return\n",
    "    \n",
    "class MAP_REDUCE:\n",
    "    \"\"\"_summary_\n",
    "    This is good for jobs that are I/O bound,makes no sense for computation bound jobs,\n",
    "    Only use this class to simulate MAP-REDUCE process, other wise simply use functools.map,\n",
    "    Or, Multiprocessing Pool could be helpful \n",
    "    __Restrictions__\n",
    "    f is assumed to out put one single argument \n",
    "    lst is a list of arguments, of which are wished to be pushed into f \n",
    "    \"\"\"\n",
    "    def __init__(self,f,lst,thread = 10,max_threads = 99,REDUCE=None):\n",
    "        assert thread < 100, 'thread can not excede 100'\n",
    "        self.f = f\n",
    "        self.lst = lst\n",
    "        self.nthread = thread\n",
    "        self.max_threads = max_threads\n",
    "        #self.Threads = {i:None for i in range(len(lst))}\n",
    "        self.GEN()\n",
    "        self.Generate_Threads()\n",
    "        #Reducr \n",
    "        if REDUCE is None:\n",
    "            from functools import reduce\n",
    "            REDUCE = lambda x: reduce(list.__add__,x)\n",
    "        self.REDUCE = REDUCE\n",
    "        \n",
    "    def GEN(self):\n",
    "        if len(self.lst) > self.max_threads:\n",
    "            _n = self.nthread\n",
    "        else:\n",
    "            _n = len(self.lst)\n",
    "        self.Threads = {i:None for i in range(_n)}  \n",
    "        self.out = {i:None for i in range(_n)}\n",
    "        \n",
    "    def FAIL_SAFE(self,RETURN = False):\n",
    "        \"Check if f(arg) is going to throw error\"\n",
    "        out = self.f(self.lst[0])\n",
    "        if RETURN :\n",
    "            return out\n",
    "        \n",
    "    def Generate_Threads(self):\n",
    "        from math import ceil\n",
    "        if len(self.lst) > self.max_threads:\n",
    "            \n",
    "            self.workload = dict()\n",
    "            #1.Devide Job into self.nthread portions \n",
    "            k = ceil(len(self.lst)/self.nthread)\n",
    "            idx = 0\n",
    "            for i in range(self.nthread):\n",
    "                self.workload[i] = self.lst[idx:idx+k]\n",
    "                idx += k \n",
    "            #2.Assign Job to threads \n",
    "            def f_iter(f,work_load):\n",
    "                return [f(arg) for arg in work_load]\n",
    "            \n",
    "            for i in range(self.nthread):\n",
    "                arg = self.workload[i]\n",
    "                t = ThreadWithReturnValue(target=f_iter, args=(self.f,(arg))) \n",
    "                self.Threads[i] = t \n",
    "                \n",
    "        else:#Generate a thread for each computation\n",
    "            for idx,arg in enumerate(self.lst):\n",
    "                t = ThreadWithReturnValue(target=self.f, args=(arg)) \n",
    "                self.Threads[idx] = t \n",
    "            \n",
    "    def Run_jobs(self):\n",
    "        for t_key in self.Threads:\n",
    "            trd = self.Threads[t_key]\n",
    "            trd.start()\n",
    "        for t_key in self.Threads:\n",
    "            trd = self.Threads[t_key]\n",
    "            self.out[t_key] = trd.join()\n",
    "            \n",
    "    def OUT(self):\n",
    "        from functools import reduce\n",
    "        self.FAIL_SAFE()\n",
    "        try:\n",
    "            self.Run_jobs()\n",
    "        except RuntimeError:\n",
    "            pass \n",
    "        return self.REDUCE(list(self.out.values()))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for o in self.OUT():\n",
    "            yield o "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Unit\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "MR = MAP_REDUCE(f,range(1000))\n",
    "assert list(map(f,range(1000))) == MR.OUT(),'MR should generate same results as map'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Example, word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word count example\n",
    "with open('word.txt','r') as INfile:\n",
    "    word_str = [l.strip() for l in INfile.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_count(STR):\n",
    "    lst_words = STR.split(' ')\n",
    "    out_dict = {}\n",
    "    for word in lst_words:\n",
    "        if word not in out_dict:\n",
    "            out_dict[word] = 1\n",
    "        else:\n",
    "            out_dict[word] += 1 \n",
    "    return out_dict\n",
    "\n",
    "def word_count_merger(c1,c2):\n",
    "    out = c1 \n",
    "    for word in c2:\n",
    "        if word in c1:\n",
    "            out[word] += c2[word]\n",
    "        else:\n",
    "            out[word] = c2[word]\n",
    "    return out \n",
    "\n",
    "def MERGER(list_wc):\n",
    "    from functools import reduce\n",
    "    return reduce(word_count_merger,list_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_word = MAP_REDUCE(line_count,lst = word_str,REDUCE = MERGER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_word.OUT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 1,\n",
       " 'count': 1,\n",
       " 'from': 1,\n",
       " 'Wikipedia': 1,\n",
       " 'the': 1,\n",
       " 'free': 1,\n",
       " 'encyclopedia': 1}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MR_word.FAIL_SAFE(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: None,\n",
       " 1: None,\n",
       " 2: None,\n",
       " 3: None,\n",
       " 4: None,\n",
       " 5: None,\n",
       " 6: None,\n",
       " 7: None,\n",
       " 8: None,\n",
       " 9: None,\n",
       " 10: None,\n",
       " 11: None,\n",
       " 12: None,\n",
       " 13: None,\n",
       " 14: None,\n",
       " 15: None,\n",
       " 16: None,\n",
       " 17: None,\n",
       " 18: None,\n",
       " 19: None,\n",
       " 20: None,\n",
       " 21: None,\n",
       " 22: None,\n",
       " 23: None,\n",
       " 24: None,\n",
       " 25: None,\n",
       " 26: None,\n",
       " 27: None,\n",
       " 28: None,\n",
       " 29: None,\n",
       " 30: None,\n",
       " 31: None,\n",
       " 32: None,\n",
       " 33: None,\n",
       " 34: None,\n",
       " 35: None,\n",
       " 36: None,\n",
       " 37: None,\n",
       " 38: None,\n",
       " 39: None,\n",
       " 40: None,\n",
       " 41: None,\n",
       " 42: None,\n",
       " 43: None}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MR_word.out"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51a7bf737bf6718c23aa77cd2d8731d550543385b29b1ef866b66571bc75d835"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('msca')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
